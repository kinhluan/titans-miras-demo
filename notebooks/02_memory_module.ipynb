{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 \u2014 Memory Module: MLP L\u00e0 B\u1ed9 Nh\u1edb D\u00e0i H\u1ea1n\n",
    "\n",
    "Trong Titans, b\u1ed9 nh\u1edb d\u00e0i h\u1ea1n **kh\u00f4ng ph\u1ea3i vector c\u1ed1 \u0111\u1ecbnh** m\u00e0 l\u00e0 **tr\u1ecdng s\u1ed1 c\u1ee7a m\u1ed9t m\u1ea1ng MLP**.\n",
    "\n",
    "**\u00dd t\u01b0\u1edfng:**\n",
    "- **Tr\u1ecdng s\u1ed1 MLP = b\u1ed9 nh\u1edb** \u2014 th\u00f4ng tin \u0111\u01b0\u1ee3c l\u01b0u trong c\u00e1ch MLP bi\u1ebfn \u0111\u1ed5i input\n",
    "- **\u0110\u1ecdc b\u1ed9 nh\u1edb** = forward pass qua MLP\n",
    "- **Ghi b\u1ed9 nh\u1edb** = c\u1eadp nh\u1eadt tr\u1ecdng s\u1ed1 MLP\n",
    "- **Surprise gating**: ch\u1ec9 ghi khi surprise cao (effective_lr = write_lr \u00d7 surprise_score)\n",
    "- **Forgetting**: weight decay \u0111\u1ec3 qu\u00ean th\u00f4ng tin c\u0169"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from titans_memory import MemoryModule\n",
    "\n",
    "torch.manual_seed(42)\n",
    "mem = MemoryModule(input_dim=4, memory_dim=16, forget_rate=0.0, write_lr=0.01)\n",
    "\n",
    "x = torch.randn(4)\n",
    "print(\"=== \u0110\u1ecdc b\u1ed9 nh\u1edb (tr\u01b0\u1edbc khi ghi) ===\")\n",
    "output_before = mem.read(x)\n",
    "print(f\"Memory output: {output_before.tolist()}\")\n",
    "\n",
    "print(\"\\n=== Ghi v\u1edbi surprise TH\u1ea4P (score=0.0) ===\")\n",
    "mem.write(x, surprise_score=torch.tensor(0.0))\n",
    "output_after_low = mem.read(x)\n",
    "print(f\"Memory output: {output_after_low.tolist()}\")\n",
    "print(f\"Thay \u0111\u1ed5i: {torch.allclose(output_before, output_after_low)} (kh\u00f4ng \u0111\u1ed5i)\")\n",
    "\n",
    "print(\"\\n=== Ghi v\u1edbi surprise CAO (score=1.0) ===\")\n",
    "mem.write(x, surprise_score=torch.tensor(1.0))\n",
    "output_after_high = mem.read(x)\n",
    "print(f\"Memory output: {output_after_high.tolist()}\")\n",
    "print(f\"Thay \u0111\u1ed5i: {not torch.allclose(output_before, output_after_high)} (\u0111\u00e3 thay \u0111\u1ed5i!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise-Gated Writes\n",
    "\n",
    "C\u00f4ng th\u1ee9c c\u1eadp nh\u1eadt: `effective_lr = write_lr \u00d7 surprise_score`\n",
    "\n",
    "- `surprise_score \u2248 0` \u2192 `effective_lr \u2248 0` \u2192 **kh\u00f4ng c\u1eadp nh\u1eadt** (\u0111\u00e3 bi\u1ebft r\u1ed3i)\n",
    "- `surprise_score = 1.0` \u2192 `effective_lr = write_lr` \u2192 **c\u1eadp nh\u1eadt m\u1ea1nh** (th\u00f4ng tin m\u1edbi!)\n",
    "\n",
    "\u0110i\u1ec1u n\u00e0y gi\u1ed1ng c\u00e1ch b\u1ea1n h\u1ecdc: \u0111\u1ecdc l\u1ea1i \u0111i\u1ec1u \u0111\u00e3 bi\u1ebft th\u00ec kh\u00f4ng nh\u1edb th\u00eam g\u00ec, nh\u01b0ng g\u1eb7p th\u00f4ng tin ho\u00e0n to\u00e0n m\u1edbi th\u00ec ghi nh\u1edb ngay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "mem = MemoryModule(input_dim=1, memory_dim=8, forget_rate=0.0, write_lr=0.05)\n",
    "\n",
    "# Ghi nhi\u1ec1u l\u1ea7n v\u1edbi c\u00e1c surprise score kh\u00e1c nhau, theo d\u00f5i weight thay \u0111\u1ed5i\n",
    "surprise_levels = [0.0, 0.1, 0.5, 1.0, 0.0, 0.0, 2.0, 0.0]\n",
    "weight_changes = []\n",
    "prev_weights = [p.data.clone() for p in mem.memory_net.parameters()]\n",
    "\n",
    "for score in surprise_levels:\n",
    "    x = torch.tensor([3.14])\n",
    "    mem.write(x, surprise_score=torch.tensor(score))\n",
    "    curr_weights = [p.data.clone() for p in mem.memory_net.parameters()]\n",
    "    change = sum((c - p).abs().sum().item() for c, p in zip(curr_weights, prev_weights))\n",
    "    weight_changes.append(change)\n",
    "    prev_weights = curr_weights\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5), sharex=True)\n",
    "ax1.bar(range(len(surprise_levels)), surprise_levels, color=\"#FF9800\", alpha=0.8)\n",
    "ax1.set_ylabel(\"Surprise Score\")\n",
    "ax1.set_title(\"Surprise Score vs Memory Weight Changes\")\n",
    "\n",
    "ax2.bar(range(len(weight_changes)), weight_changes, color=\"#4CAF50\", alpha=0.8)\n",
    "ax2.set_ylabel(\"T\u1ed5ng |\u0394weight|\")\n",
    "ax2.set_xlabel(\"Write step\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\u01a1 Ch\u1ebf Qu\u00ean (Forgetting)\n",
    "\n",
    "Memory c\u0169ng c\u1ea7n **qu\u00ean** \u2014 n\u1ebfu kh\u00f4ng, th\u00f4ng tin c\u0169 s\u1ebd t\u00edch t\u1ee5 v\u00e0 \"l\u1ea5n \u00e1t\" th\u00f4ng tin m\u1edbi.\n",
    "\n",
    "Titans d\u00f9ng **weight decay th\u00edch \u1ee9ng**: `weights *= (1 - forget_rate)` m\u1ed7i timestep.\n",
    "\n",
    "- `forget_rate = 0.0` \u2192 kh\u00f4ng qu\u00ean (nh\u1edb m\u00e3i)\n",
    "- `forget_rate = 0.05` \u2192 qu\u00ean nhanh (ch\u1ec9 nh\u1edb g\u1ea7n \u0111\u00e2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "for rate in [0.0, 0.005, 0.02, 0.05]:\n",
    "    torch.manual_seed(42)\n",
    "    mem = MemoryModule(input_dim=1, memory_dim=16, forget_rate=rate, write_lr=0.01)\n",
    "\n",
    "    # Ghi 1 l\u1ea7n r\u1ed3i theo d\u00f5i memory norm gi\u1ea3m d\u1ea7n\n",
    "    mem.write(torch.tensor([5.0]), surprise_score=torch.tensor(1.0))\n",
    "    norms = []\n",
    "    for _ in range(100):\n",
    "        norm = sum(p.data.norm().item() for p in mem.memory_net.parameters())\n",
    "        norms.append(norm)\n",
    "        mem.apply_forgetting()\n",
    "\n",
    "    ax.plot(norms, linewidth=2, label=f\"forget_rate={rate}\")\n",
    "\n",
    "ax.set_xlabel(\"Timestep sau khi ghi\")\n",
    "ax.set_ylabel(\"T\u1ed5ng Memory Weight Norm\")\n",
    "ax.set_title(\"Hi\u1ec7u \u1ee9ng Forgetting: Weight decay theo th\u1eddi gian\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K\u1ebft lu\u1eadn\n",
    "\n",
    "- **MLP weights = b\u1ed9 nh\u1edb**: c\u00e1ch ti\u1ebfp c\u1eadn s\u00e1ng t\u1ea1o, kh\u00e1c ho\u00e0n to\u00e0n RNN truy\u1ec1n th\u1ed1ng\n",
    "- **Surprise gating**: ch\u1ec9 ghi nh\u1edb khi th\u00f4ng tin th\u1ef1c s\u1ef1 m\u1edbi l\u1ea1\n",
    "- **Forgetting**: t\u1ef1 \u0111\u1ed9ng lo\u1ea1i b\u1ecf th\u00f4ng tin c\u0169, gi\u1eef b\u1ed9 nh\u1edb \"t\u01b0\u01a1i m\u1edbi\"\n",
    "\n",
    "\u2192 Ba c\u01a1 ch\u1ebf n\u00e0y k\u1ebft h\u1ee3p t\u1ea1o n\u00ean h\u1ec7 th\u1ed1ng b\u1ed9 nh\u1edb d\u00e0i h\u1ea1n th\u00f4ng minh."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}